# KnowBase Embeddings-Only Configuration
# Use this when you already have preprocessed documents and only need to generate embeddings

config_name: "embeddings_only"
description: "Only embedding generation (skip preprocessing)"
created_at: "2025-12-04"

preprocessing:
  chunk_size: 512
  chunk_overlap: 50
  min_chunk_size: 50
  remove_html: true
  normalize_whitespace: true
  remove_special_chars: false
  lowercase: false
  language: "en"

embedding:
  model_name: "BAAI/bge-large-en-v1.5"
  device: "auto"
  batch_size: 32
  cache_dir: "~/.cache/huggingface"
  model_cache_enabled: true
  precision: "fp32"

vector_store:
  db_path: "./data/vector_db"
  collection_name: "documents"
  distance_metric: "cosine"
  persist_directory: true

retrieval:
  top_k: 5
  similarity_threshold: 0.0
  rerank_enabled: false
  rerank_model: null
  filter_by_metadata: {}

ai_search:
  enabled: false
  llm_provider: "openai"
  llm_model: "gpt-4-mini"
  llm_temperature: 0.7
  llm_max_tokens: 2000
  llm_api_key: null
  query_analyzer_enabled: true
  query_clarity_threshold: 0.85
  query_rewriter_enabled: true
  clarification_enabled: true
  conversation_window: 10
  show_thinking: true

clustering:
  enabled: false
  min_cluster_size: 5
  min_samples: 5
  clustering_metric: "cosine"
  use_umap: true
  umap_n_neighbors: 15
  umap_min_dist: 0.1
  umap_n_components: 3

# KEY DIFFERENCE: Skip preprocessing, only run embedding + indexing
pipeline:
  run_preprocessing: false  # ← SKIP
  run_embedding: true       # ← RUN
  run_indexing: true        # ← RUN
  run_retrieval: false
  run_ai_search: false
  run_clustering: false
  skip_existing: false
  save_intermediate: false
  parallel_processing: true
  num_workers: -1
  verbose: false
  log_level: "INFO"
