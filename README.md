# ğŸ§  KnowBase â€” ricerca semantica immersiva per documenti

Un toolkit pratico e immediato per trasformare raccolte di documenti (SRT, PDF, TXT, Markdown...) in una knowledge base ricercabile semanticamente. Usa modelli di embedding diversi, collezioni isolate per modello e una UI web integrata per esplorare i risultati.

Per sviluppatori e power users: semplice da estendere, pensato per testare modelli e pipeline diverse senza rompere gli indici esistenti.

**âœ¨ Highlights**

- ğŸ¤– **Multi-model**: supporto per `BAAI/bge-large-en-v1.5` e `google/embeddinggemma-300m` (e altri tramite adapter)
- ğŸ” **Collezioni isolate**: ogni modello scrive in collezioni separate in ChromaDB
- ğŸ”„ **Pipeline modulare**: parsing â†’ chunking â†’ embeddings â†’ store â†’ retrieval
- ğŸ›ï¸ **Interfacce**: script CLI per batch, API programmatica e interfaccia Streamlit per esplorazione

**âš¡ Pronto per prototipi e sperimentazione**: caching dei modelli, selezione dinamica del device (CPU, CUDA, MPS), e helper per confronto di qualitÃ  tra modelli.

**ğŸš€ Quick TL;DR (esempio rapido)**

1. ğŸ“¦ Crea e attiva un virtualenv:

```
python -m venv .venv
source .venv/bin/activate
```

2. ğŸ“¥ Installa dipendenze:

```
pip install -r requirements.txt
```

3. âš™ï¸ Processa file (default model impostato in `.env`):

```
python scripts/process_subtitles.py --input subtitles/ --output data/processed
```

4. ğŸ” Cerca nei dati indicizzati:

```
python scripts/query_subtitles.py "come potrei rinvasare un'orchidea?"
```

5. ğŸŒ Avvia la UI:

```
./start_viewer.sh
```

**ğŸ’¡ PerchÃ© Ã¨ figa?**

- âš¡ Cambio modello al volo: puoi confrontare embedding di modelli diversi senza mescolare i dati.
- ğŸ”Œ Facilmente estendibile: il pattern a adapter rende l'aggiunta di un nuovo modello minimale.
- â±ï¸ Pensato per SRT e documenti con contesto temporale (subtitle-aware chunking).

**ğŸ“ Struttura chiave del repository**

- ğŸ§  `src/embeddings/` â€” adapter, loader e pipeline per generare embeddings.
- ğŸ”¤ `src/preprocessing/` â€” parser per SRT, chunker, normalizzazione testo.
- ğŸ—„ï¸ `src/vector_store/` â€” gestione ChromaDB, naming per collezioni model-specific.
- ğŸ› ï¸ `scripts/` â€” script CLI per processare, migrare e interrogare il DB.
- ğŸ¨ `streamlit_app.py` â€” interfaccia web per esplorare ricerche e cambiare modello.

**ğŸ“Œ Scorci pratici**

- ğŸ“š Collezioni:
  - BGE: `document_embeddings_bge_large`
  - Gemma: `document_embeddings_gemma_300m`
- ğŸ“„ File utili: `requirements.txt`, `start_viewer.sh`, `scripts/process_subtitles.py`

ğŸ“– Vuoi andare oltre? Apri `USER_GUIDE.md` per istruzioni tecniche dettagliate, esempi di CLI e snippet per usare le pipeline dal codice Python.
