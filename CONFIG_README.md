# Configuration System - Quick Reference

## ğŸ¯ What You Can Do

âœ… **Run complete pipeline** â€“ Preprocess â†’ Embed â†’ Index  
âœ… **Run partial pipelines** â€“ Only embeddings, only search, only RAG  
âœ… **Save/load configurations** â€“ YAML and JSON support  
âœ… **Use from CLI or Python** â€“ Same config system everywhere  
âœ… **Override via environment** â€“ ENV variables override config files  
âœ… **Strongly validated** â€“ Pydantic ensures all configs are correct

---

## ğŸ“ Configuration Files

### Presets (in `config/presets/`)

```
config/presets/
â”œâ”€â”€ full_pipeline.yaml       # All stages: prep â†’ embed â†’ index
â”œâ”€â”€ embeddings_only.yaml     # Skip preprocessing, just embed
â”œâ”€â”€ search_only.yaml         # Skip indexing, just search
â”œâ”€â”€ rag_only.yaml            # Skip search, just RAG/LLM
â””â”€â”€ custom_template.yaml     # Template for your config
```

---

## ğŸš€ Quick Start

### CLI Usage

```bash
# Full pipeline
knowbase load --config config/presets/full_pipeline.yaml --input ./subtitles

# Only embeddings
knowbase load --config config/presets/embeddings_only.yaml --input ./docs

# Only search
knowbase search --config config/presets/search_only.yaml --query "orchids"

# Only RAG
knowbase ask --config config/presets/rag_only.yaml "How to grow orchids?"
```

### Python Usage

```python
from src.utils.config_manager import ConfigManager, get_preset_config
from pathlib import Path

# Option 1: Use preset
config = get_preset_config("full_pipeline")

# Option 2: Load from file
mgr = ConfigManager(config_file=Path("config/presets/full_pipeline.yaml"))

# Option 3: Override specific values
mgr.merge_with_dict({
    "embedding": {"batch_size": 64},
    "ai_search": {"llm_temperature": 0.5}
})

# Get specific configs
embedding_cfg = mgr.get_embedding_config()
rag_cfg = mgr.get_ai_search_config()
```

---

## ğŸ”§ Configuration Sections

| Section           | Purpose           | Key Options                               |
| ----------------- | ----------------- | ----------------------------------------- |
| **embedding**     | Model & hardware  | model_name, device, batch_size            |
| **preprocessing** | Document cleaning | chunk_size, remove_html, lowercase        |
| **vector_store**  | ChromaDB settings | db_path, collection_name, distance_metric |
| **retrieval**     | Search settings   | top_k, similarity_threshold, rerank       |
| **ai_search**     | LLM/RAG settings  | llm_provider, llm_model, temperature      |
| **clustering**    | Analysis settings | min_cluster_size, use_umap                |
| **pipeline**      | What to run       | run_preprocessing, run_embedding, etc     |

---

## ğŸ›ï¸ Common Customizations

### Change Embedding Model

```yaml
embedding:
  model_name: "google/embeddinggemma-300m" # Faster than BAAI
  batch_size: 64
```

### Use Different LLM

```yaml
ai_search:
  llm_provider: "anthropic"
  llm_model: "claude-3-opus"
```

### Adjust Chunk Size

```yaml
preprocessing:
  chunk_size: 256 # Smaller chunks
  chunk_overlap: 50
```

### Filter Search Results

```yaml
retrieval:
  top_k: 10
  similarity_threshold: 0.5 # Only results > 0.5 similarity
```

---

## ğŸ” Environment Variables

Override any config value via environment:

```bash
# Embedding
export MODEL_NAME="google/embeddinggemma-300m"
export BATCH_SIZE=64
export DEVICE=cuda

# LLM/RAG
export LLM_PROVIDER=openai
export LLM_TEMPERATURE=0.7
export OPENAI_API_KEY=sk-...

# Pipeline
export VERBOSE=true
export LOG_LEVEL=DEBUG
```

---

## ğŸ“Š Pipeline Execution Examples

### Example 1: Full Pipeline

```yaml
pipeline:
  run_preprocessing: true   âœ“
  run_embedding: true       âœ“
  run_indexing: true        âœ“
  run_retrieval: false
  run_ai_search: false
```

**Use:** Raw documents â†’ Indexed vectors

### Example 2: Search Only

```yaml
pipeline:
  run_preprocessing: false
  run_embedding: false
  run_indexing: false
  run_retrieval: true       âœ“
  run_ai_search: false
```

**Use:** Already indexed, just search

### Example 3: RAG Only

```yaml
pipeline:
  run_preprocessing: false
  run_embedding: false
  run_indexing: false
  run_retrieval: false
  run_ai_search: true       âœ“
```

**Use:** Ask questions with LLM

---

## ğŸ“ Create Custom Config

1. Copy template:

```bash
cp config/presets/custom_template.yaml config/my_config.yaml
```

2. Edit `config/my_config.yaml`

3. Use it:

```bash
knowbase load --config config/my_config.yaml --input ./docs
```

Or in Python:

```python
mgr = ConfigManager(config_file=Path("config/my_config.yaml"))
```

---

## âœ… Testing Configuration

```bash
python scripts/test_config.py
```

This runs 8 tests to verify the configuration system works correctly.

---

## ğŸ“š Full Documentation

See `docs/CONFIGURATION.md` for detailed documentation with:

- All configuration options explained
- Usage examples for every scenario
- Troubleshooting guide
- Environment variable reference

---

## ğŸ’¡ Tips

- **Save successful configs** â€“ Keep configs that work for your data
- **Use presets as templates** â€“ Don't start from scratch
- **Version your configs** â€“ `git` them like code
- **Document your choices** â€“ Add comments in YAML
- **Test before production** â€“ Run test with `test_config.py`
